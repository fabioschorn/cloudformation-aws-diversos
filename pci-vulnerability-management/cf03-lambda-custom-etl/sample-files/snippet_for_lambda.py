import boto3
import sys
sys.path.append('/opt/python')
import psycopg2
import psycopg2.extras
import csv
import os
import json

# AWS Clients
s3 = boto3.client('s3')
secrets_client = boto3.client('secretsmanager')

# Retrieve env variables
S3_BUCKET = os.environ['S3_BUCKET']
S3_PATH = os.environ['S3_PATH']
SECRET_NAME = os.environ['SECRET_NAME']

def get_db_credentials():
    """Retrieve RDS credentials from AWS Secrets Manager"""
    try:
        response = secrets_client.get_secret_value(SecretId=SECRET_NAME)
        secret_dict = json.loads(response["SecretString"])
        return secret_dict
    except Exception as e:
        print(f"Error retrieving secret: {e}")
        raise

def lambda_handler(event, context):
    """Lambda function to read CSV from S3 and insert into PostgreSQL"""

    # Get RDS credentials from Secrets Manager
    credentials = get_db_credentials()

    # Identify latest CSV file
    response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=S3_PATH)
    if "Contents" not in response:
        print("No files found in processed PCI directory.")
        return {"status": "No CSV found"}

    latest_file = max(response["Contents"], key=lambda obj: obj["LastModified"])
    file_key = latest_file["Key"]
    print(f"Processing file: s3://{S3_BUCKET}/{file_key}")

    # Download CSV data
    obj = s3.get_object(Bucket=S3_BUCKET, Key=file_key)
    csv_data = obj['Body'].read().decode('utf-8').splitlines()
    csv_reader = csv.DictReader(csv_data, delimiter=';')  # Using DictReader for better handling

    # Define expected column headers (ensure these match the DB table schema)
    expected_columns = [
        "IP", "DNS", "OS", "QID", "Title", "Severity",
        "CVE ID", "Vendor Reference", "Threat", "Impact",
        "Solution", "PCI Vuln", "Category"
    ]

    print(f"CSV Headers: {csv_reader.fieldnames}")  # Debugging

    # Validate if CSV headers match expected schema
    if not set(expected_columns).issubset(set(csv_reader.fieldnames)):
        print("CSV headers do not match the expected columns.")
        return {"status": "CSV Header Mismatch"}

    # Connect to RDS PostgreSQL
    try:
        conn = psycopg2.connect(
            host=credentials["host"],
            port=credentials["port"],
            database=credentials["database"],
            user=credentials["username"],
            password=credentials["password"]
        )
        cursor = conn.cursor()
    except Exception as e:
        print(f"Database connection error: {e}")
        return {"status": "DB Connection Failed"}

    # Prepare insert statement
    insert_query = """
    INSERT INTO vulnerabilities (ip, dns, os, qid, title, severity, cve_id, vendor_ref, threat, impact, solution, pci_vuln, category)
    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """

    row_count = 0
    for row in csv_reader:
        try:
            # Extract and clean the data
            ip = row["IP"]
            dns = row["DNS"]
            os_version = row["OS"]
            qid = int(row["QID"])  # Convert QID to integer
            title = row["Title"]
            severity = int(row["Severity"])  # Convert Severity to integer
            cve_id = row["CVE ID"]
            vendor_ref = row["Vendor Reference"]
            threat = row["Threat"]
            impact = row["Impact"]
            solution = row["Solution"]
            pci_vuln = True if row["PCI Vuln"].strip().lower() == "yes" else False  # Convert "yes"/"no" to boolean
            category = row["Category"]

            # Execute query with proper formatting
            cursor.execute(insert_query, (ip, dns, os_version, qid, title, severity, cve_id, vendor_ref, threat, impact, solution, pci_vuln, category))
            row_count += 1

        except Exception as e:
            print(f"Skipping row due to error: {e}")  # Log the problematic row and continue

    # Commit and close connection
    conn.commit()
    cursor.close()
    conn.close()

    print(f"Inserted {row_count} rows into PostgreSQL.")
    return {"status": "Success", "rows_inserted": row_count}